#!/bin/bash
#
# GPT Project Directory Processor
# =========================
# Securely processes and formats project files for GPT analysis
#
# Features:
# - Secure file processing with strict permissions
# - Parallel processing support
# - Comprehensive error handling
# - File type validation
# - Directory traversal protection
#
# Usage:
#   gpt_project [-p path] -e ext1,ext2 [-x dir1,dir2] [-o out] [-m size] [-n max] [-v] [-d]
#
# Author: kostevski
# License: MIT
# Version: 0.1.0
# Platform: Darwin/macOS
# Requirements:
#   - bash 4.0+
set -o errexit
set -o nounset
set -o pipefail

if [ "${BASH_VERSINFO[0]}" -lt 3 ]; then
  echo "Error: This script requires bash version 3 or higher" >&2
  exit 1
fi

#######################################
# Constants and Configuration
#######################################
readonly VERSION="0.1.0"
readonly SCRIPT_NAME="${0##*/}"

# Memory units for readable configuration
readonly KB=$((1024))
readonly MB=$((KB * 1024))

# System limits and defaults
readonly DEFAULT_MAX_DEPTH=10
readonly DEFAULT_MAX_SIZE=$((50 * MB))
readonly DEFAULT_MAX_FILES=1000
readonly DEFAULT_JOBS=$(nproc 2>/dev/null || sysctl -n hw.logicalcpu || echo 4)

# Output formatting
readonly MARKDOWN_FENCE="\`\`\`"
readonly MARKDOWN_HEADER_PREFIX="##"

readonly ALLOWED_PATHS=(
  "${PWD}"          # Current working directory
  "${TMPDIR:-/tmp}" # Temporary directory
  "${HOME}"         # User's home directory
)

# Default excluded directories
readonly -a DEFAULT_EXCLUDES=(
  '.git'
  'bin'
  'venv'
  '.venv'
  'env'
  '.env'
  'dist'
  'build'
  '.idea'
  '.vscode'
  'tmp'
  'temp'
  'log'
  'logs'
  'cache'
  '.cache'
  '.output'
  'out'
  'test'
)

# Error codes
readonly E_PERMISSION=85 # Permission denied
readonly E_RESOURCE=86   # Resource allocation failure
readonly E_SECURITY=87   # Security violation
readonly E_IO=88         # I/O operation failure
readonly E_USAGE=89      # Invalid usage
readonly E_SYSTEM=90    # System command failure
readonly E_PATH=92       # Path not available

#######################################
# Global state configuration
#######################################
# Environment variable overrides
declare -r GPT_PROJECT_MAX_SIZE="${GPT_PROJECT_MAX_SIZE:-${DEFAULT_MAX_SIZE}}"
declare -r GPT_PROJECT_MAX_FILES="${GPT_PROJECT_MAX_FILES:-${DEFAULT_MAX_FILES}}"
declare -r GPT_PROJECT_MAX_DEPTH="${GPT_PROJECT_MAX_DEPTH:-${DEFAULT_MAX_DEPTH}}"
declare -r GPT_PROJECT_MAX_JOBS="${GPT_PROJECT_MAX_JOBS:-${DEFAULT_JOBS}}"
declare -r GPT_PROJECT_EXCLUDE_DIRS="${GPT_PROJECT_EXCLUDE_DIRS:-}"
declare -r GPT_PROJECT_OUTPUT="${GPT_PROJECT_OUTPUT:-/dev/stdout}"

# Runtime state
declare INPUT_PATH="${PWD}"
declare OUTPUT="${GPT_PROJECT_OUTPUT}"
declare -a EXCLUDE_DIRS=("${DEFAULT_EXCLUDES[@]}")
[[ -n "${GPT_PROJECT_EXCLUDE_DIRS}" ]] && parse_exclude_dirs "${GPT_PROJECT_EXCLUDE_DIRS}"

declare -a EXTENSIONS=()
declare MAX_SIZE="${GPT_PROJECT_MAX_SIZE}"
declare MAX_FILES="${GPT_PROJECT_MAX_FILES}"
declare MAX_DEPTH="${GPT_PROJECT_MAX_DEPTH}"
declare MAX_JOBS="${GPT_PROJECT_MAX_JOBS}"

# Runtime flags
declare -i DRY_RUN=0
declare -i VERBOSE=0
declare -i DEBUG=0

# Stats
declare -i STATS_PROCESSED=0
declare -i STATS_FAILED=0
declare -i STATS_START_TIME
declare -i STATS_END_TIME

declare TEMP_DIR
declare -a TMP_FILES=()

function usage() {
  cat <<EOF

Usage: ${SCRIPT_NAME} [OPTIONS] [PATH]

Process and format project files for GPT analysis.

Options:
  -d, --debug              Enable debug output
  -e, --extensions=LIST    Comma-separated list of file extensions to process
  -h, --help              Display this help and exit
  -j, --jobs=N            Number of parallel jobs (default: auto)
  -m, --max-size=BYTES    Maximum file size in bytes (0 for unlimited)
  -n, --dry-run           Show what would be done without doing it
  -o, --output=FILE       Output file (default: stdout)
  -q, --quiet             Suppress non-error messages
  -v, --verbose           Enable verbose output
  -x, --exclude=DIRS      Comma-separated list of directories to exclude
      --version           Display version information and exit

Examples:
  ${SCRIPT_NAME} .                        Process current directory
  ${SCRIPT_NAME} --output=out.txt src/    Process src directory to out.txt
  ${SCRIPT_NAME} --max-size=1048576 lib/  Process files under 1MB in lib/

Version: ${VERSION}
EOF
}

function version() {
  echo "${SCRIPT_NAME} ${VERSION}"
}

#######################################
# Output and logging functions
#######################################

# Log levels
declare -r LOG_LEVEL_ERROR=0
declare -r LOG_LEVEL_WARN=1
declare -r LOG_LEVEL_INFO=2
declare -r LOG_LEVEL_DEBUG=3

# Environment variable overrides for logging
declare LOG_LEVEL
LOG_LEVEL=${LOG_LEVEL_INFO}

# Terminal colors if output is a terminal
if [[ -t 2 ]]; then
    readonly RED=$'\033[0;31m'
    readonly YELLOW=$'\033[0;33m'
    readonly GREEN=$'\033[0;32m'
    readonly BLUE=$'\033[0;34m'
    readonly RESET=$'\033[0m'
else
    readonly RED=""
    readonly YELLOW=""
    readonly GREEN=""
    readonly BLUE=""
    readonly RESET=""
fi

# Central logging function with structured output
# Args:
#   $1 - Log level (numeric)
#   $2 - Log level name (string)
#   $3 - Message to log
#   $4 - Context (optional JSON-like string)
# Returns:
#   0 if message was logged, 1 if suppressed by level
function _log() {
    local -r level_num="$1"
    local -r level_name="$2"
    local -r message="$3"
    local -r context="${4:-}"

    [[ ${level_num} -gt ${LOG_LEVEL} ]] && return 1

    local color=""
    case "${level_name}" in
        ERROR) color="${RED}" ;;
        WARN)  color="${YELLOW}" ;;
        INFO)  color="${GREEN}" ;;
        DEBUG) color="${BLUE}" ;;
        *)     color="${RESET}" ;;
    esac

    local log_line="${color}${level_name}${RESET}"
    log_line+=" [${SCRIPT_NAME}] ${message}"
    [[ -n "${context}" ]] && log_line+=" ${context}"

    printf "%s\n" "${log_line}" >&2
    return 0
}

# Enhanced logging interfaces with context support
function log_error() {
    local -r message="$1"
    local -r code="${2:-1}"
    local -r context="${3:-}"
    _log ${LOG_LEVEL_ERROR} "ERROR" "${message}" "${context}"
    return "${code}"
}

function log_warn() {
    local -r message="$1"
    local -r context="${2:-}"
    _log ${LOG_LEVEL_WARN} "WARN" "${message}" "${context}"
}

function log_info() {
    local -r message="$1"
    local -r context="${2:-}"
    _log ${LOG_LEVEL_INFO} "INFO" "${message}" "${context}"
}

function log_debug() {
    local -r message="$1"
    local -r context="${2:-}"
    _log ${LOG_LEVEL_DEBUG} "DEBUG" "${message}" "${context}"
}

# Creates a secure temporary file with restricted permissions
# The file path is added to TMP_FILES array for cleanup
# Returns:
#   Path to temporary file on stdout
#   E_IO on file creation failure
#   E_PERMISSION on chmod failure
function create_temp_file() {

  local temp_file
  temp_file=$(mktemp -t "temp" -p "${TEMP_DIR}") || return ${E_IO}

  chmod 600 "${temp_file}" || {
    rm -f "${temp_file}"
    log_error "Failed to set permissions on temporary file"
    return ${E_PERMISSION}
  }

  TMP_FILES[${#TMP_FILES[@]}]="${temp_file}"
  echo "${temp_file}"
  return 0
}

#######################################
# File validation and processing
#######################################

# Validates if a file has one of the allowed extensions
# Args:
#   $1 - File path to check
# Returns:
#   0 if file extension matches allowed list
#   1 if extension is not in allowed list
function is_valid_extension() {
  local -r file="$1"
  local -r ext="${file##*.}"

  [[ " ${EXTENSIONS[*]} " == *" ${ext} "* ]]
}

# Validates file for processing
# Args:
#   $1 - File path to validate
# Returns:
#   0 if valid, non-zero otherwise
function is_valid_file() {
  local -r file="$1"
  local -r basename="$(basename "${file}")"

  # Skip hidden files
  [[ "${basename}" == .* ]] && return 1

  # Basic checks
  [[ ! -f "${file}" ]] && return "${E_IO}"
  [[ ! -r "${file}" ]] && return "${E_PERMISSION}"

  # Size check if configured
  if ((MAX_SIZE > 0)); then
    local size
    size=$(stat -f %z "${file}" 2>/dev/null) || return ${E_IO}
    ((size > MAX_SIZE)) && return 1
  fi

  return 0
}

function find_files() {
  local dir="$1"
  local -a find_cmd=(
    find
    -L
    "${dir}"
    -type f
  )

  # Add exclude patterns
  for exclude in "${EXCLUDE_DIRS[@]}"; do
    find_cmd+=(-not -path "\"*/${exclude}/*\"")
  done

  # Add extension patterns with -o (OR) operator
  local first=true
  for ext in "${EXTENSIONS[@]}"; do
    if $first; then
      find_cmd+=(-name "\"*.${ext}\"")
      first=false
    else
      find_cmd+=(-o -name "\"*.${ext}\"")
    fi
  done

  # Add max depth if specified
  if ((MAX_DEPTH > 0)); then
    find_cmd+=(-maxdepth "${MAX_DEPTH}")
  fi
  find_cmd+=(-print0)

  # Debug output
  if ((DEBUG)); then
    log_debug "Find command: ${find_cmd[*]}"
  fi

  # Execute find command with proper error handling
  eval "${find_cmd[*]}" 2>/dev/null || {
    log_error "Failed to execute find command"
    return ${E_SYSTEM}
  }
}

# Detects and returns the appropriate file type/language based on extension
# Args:
#   $1 - File path
# Returns:
#   Language identifier string on stdout
function detect_file_type() {
  local -r file="$1"
  local -r extension="${file##*.}"

  # Map common extensions to their language/type
  case "${extension}" in
    sh | bash) echo "bash" ;;
    py | pyw) echo "python" ;;
    js | jsx) echo "javascript" ;;
    ts | tsx) echo "typescript" ;;
    rb) echo "ruby" ;;
    php) echo "php" ;;
    java) echo "java" ;;
    cpp | cc | cxx) echo "cpp" ;;
    c) echo "c" ;;
    go) echo "go" ;;
    rs) echo "rust" ;;
    md | markdown) echo "markdown" ;;
    yml | yaml) echo "yaml" ;;
    json) echo "json" ;;
    xml) echo "xml" ;;
    sql) echo "sql" ;;
    *) echo "text" ;;
  esac
}

# Generates and writes the project analysis header to output file
# Including project info and directory structure
# Args:
#   $1 - Output file path
# Returns:
#   0 on success, non-zero on error
function output_header() {
  local output="$1"
  local title="GPT Project Analysis"
  local path="${INPUT_PATH}"
  {
    echo
    echo "# ${title}"
    echo
    echo "${MARKDOWN_HEADER_PREFIX} Project Information "
    echo
    echo "- **Path:** \`${path}\`"
    echo
    echo "- **Extensions:** \`${EXTENSIONS[*]}\`"
  } >>"${output}"

  # Get directory structure using tree command
  local tree_output
  if ! tree_output=$(print_tree "${INPUT_PATH}"); then
    log_error "Failed to generate directory structure"
    return ${E_IO}
  fi
  {
    echo
    echo "${MARKDOWN_HEADER_PREFIX} Directory Structure"
    echo "${MARKDOWN_FENCE}"
    echo "${tree_output}"
    echo "${MARKDOWN_FENCE}"
  } >>"${output}"

  return 0
}

# prints directory tree structure using 'tree' command if available
# falls back to 'ls' if tree is not installed
# args:
#   $1 - target directory path (defaults to input_path)
# returns:
#   directory structure as formatted string
function print_tree() {

  local target="${1:-${INPUT_PATH}}"
  local max_depth="${MAX_DEPTH:-3}"

  if command -v tree >/dev/null 2>&1; then
    local exclude_pattern
    local IFS='|'
    exclude_pattern="${DEFAULT_EXCLUDES[*]}"
    unset IFS

    tree \
      -I "${exclude_pattern}" \
      --noreport \
      --charset utf-8 \
      -L "${max_depth}" \
      "${target}"
  else
    log_debug "tree command not found, using internal implementation"
    ls -a "${target}"
  fi
}

# Main entry point for processing a target path (file or directory)
# Args:
#   $1 - Target path to process
#   $2 - Output file path
# Returns:
#   0 on success, non-zero on error
function process_target() {
  local target="$1"
  local output="$2"
  local exit_code=0

  if ! output_header "${output}"; then
    log_error "Failed creating output header"
    return 1
  fi

  if [[ -d "${target}" ]]; then
    process_directory "${target}" "${output}"
    exit_code=$?
  elif [[ -f "${target}" ]]; then
    process_file "${target}" "${output}"
    exit_code=$?
  else
    log_error "Target path not found: ${target}"
    exit_code=${E_PATH}
  fi

  return ${exit_code}
}

# Process all valid files in a directory recursively
# Args:
#   $1 - Directory path to process
#   $2 - Output file path
# Returns:
#   Number of errors encountered (0 on success)
function process_directory() {
  local dir="$1"
  local output="$2"
  local -i errors=0
  declare -a file_array

  local context="dir=${dir} output=${output}"

  while IFS= read -r -d $'\0' file; do
    file_array+=("$file")
  done < <(find_files "${INPUT_PATH}")

  if ((${#file_array[@]} == 0)); then
    log_warn "No matching files found" "${context}"
    return 0
  fi

  if ((DRY_RUN)); then
    log_info "Would process ${#file_array[@]} files" "${context}"
    return 0
  fi

  context+=" total_files=${#file_array[@]}"
  if ! process_files_parallel "${file_array[@]}" "${output}"; then
    log_error "Failed to process directory" "${context}"
    ((errors++))
  fi

  return ${errors}
}

# Signal handlers
function handle_interrupt() {
    log_warn "Received interrupt signal" "signal=INT"
    cleanup
    exit 130  # Standard exit code for SIGINT
}

function handle_term() {
    log_warn "Received termination signal" "signal=TERM"
    cleanup
    exit 143  # Standard exit code for SIGTERM
}

# Improved process_files_parallel with better job control
function process_files_parallel() {
    local -r output="${!#}"
    local -i max_jobs="${MAX_JOBS}"
    local -i active_jobs=0
    local -i failed=0
    local -i total=0
    local -i processed=0

    local -a files=("${@:1:$#-1}")
    total=${#files[@]}

    local -A pids=()
    local context="total=${total} max_jobs=${max_jobs}"
    log_debug "Starting parallel processing" "${context}"

    for file in "${files[@]}"; do
        # Wait if we've reached max jobs
        while ((active_jobs >= max_jobs)); do
            wait -n 2>/dev/null || true
            
            # Update active jobs count and check results
            for pid in "${!pids[@]}"; do
                if ! kill -0 "${pid}" 2>/dev/null; then
                    wait "${pid}" || {
                        log_error "Failed processing: ${pids[${pid}]}"
                        ((failed++))
                    }
                    unset "pids[${pid}]"
                    ((active_jobs--))
                    ((processed++))
                fi
            done
        done

        # Start new job
        (process_file "${file}" "${output}") & 
        local pid=$!
        pids["${pid}"]="${file}"
        ((active_jobs++))

        context="processed=${processed}/${total} active=${active_jobs} failed=${failed}"
        log_debug "Started job" "${context}"
    done

    # Wait for remaining jobs
    while ((active_jobs > 0)); do
        wait -n 2>/dev/null || true
        
        for pid in "${!pids[@]}"; do
            if ! kill -0 "${pid}" 2>/dev/null; then
                wait "${pid}" || {
                    log_error "Failed processing: ${pids[${pid}]}"
                    ((failed++))
                }
                unset "pids[${pid}]"
                ((active_jobs--))
                ((processed++))
                
                context="processed=${processed}/${total} active=${active_jobs} failed=${failed}"
                log_debug "Job completed" "${context}"
            fi
        done
    done

    context="total=${total} processed=${processed} failed=${failed}"
    log_info "Parallel processing completed" "${context}"
    return $((failed > 0 ? 1 : 0))
}

# Process a single file and format it for GPT analysis
# Includes file metadata and content in markdown format
# Args:
#   $1 - Input file path
#   $2 - Output file path
# Returns:
#   0 on success, non-zero on error
function process_file() {
  local input="$1"
  local output="$2"
  local -i ret=0

  local tmp_output
  tmp_output=$(create_temp_file) || return ${E_IO}

  local size
  size=$(stat -f %z "${input}" 2>/dev/null) || size="unknown"
  local context="file=${input} size=${size}"

  local file_type
  file_type=$(detect_file_type "${input}")
  context+=" type=${file_type}"

  {
    echo
    echo "${MARKDOWN_HEADER_PREFIX} File: \`${input}\`"
    echo "Size: ${size} bytes"
    echo "Type: ${file_type}"
    echo
    echo "${MARKDOWN_FENCE}${file_type}"
    cat "${input}" || ret=${E_IO}
    echo "${MARKDOWN_FENCE}"
  } >"${tmp_output}" || {
    log_error "Failed to write to temporary file" "${context}"
    ret=${E_IO}
  }
  
  if ((ret == 0)); then
    if ! cat "${tmp_output}" >>"${output}"; then
      log_error "Failed to write output" "${context}"
      ret=${E_IO}
    else
      ((STATS_PROCESSED++))
      log_debug "Processed file successfully" "${context}"
    fi
  else
    ((STATS_FAILED++))
    log_error "Failed to process file" "${context}"
  fi
  return ${ret}
}

#######################################
# Command line argument parsing
#######################################
# Parses and validates excluded directories
# Combines user-specified excludes with defaults
# Args:
#   $1 - Comma-separated list of directories
# Returns:
#   0 on success, non-zero on error
function parse_exclude_dirs() {
  local dir_list="$1"
  [[ -z "${dir_list}" ]] && return 0

  local IFS=','
  read -ra dir_array <<<"${dir_list}"
  unset IFS

  local -a combined_excludes=("${DEFAULT_EXCLUDES[@]}")

  local dir
  for dir in "${dir_array[@]}"; do
    [[ "${dir}" =~ ^[a-zA-Z0-9_.-]+$ ]] || {
      log_error "Invalid directory name format: ${dir}"
      return ${E_USAGE}
    }
    combined_excludes+=("${dir}")
  done

  EXCLUDE_DIRS=("${combined_excludes[@]}")
  return 0
}

# Parses and validates file extensions
# Args:
#   $1 - Comma-separated list of extensions
# Returns:
#   0 on success, non-zero on error
function parse_extensions() {
  local ext_list="$1"
  [[ -z "${ext_list}" ]] && {
    log_error "Extensions list cannot be empty"
    return ${E_USAGE}
  }

  # Create array from comma-separated list
  local IFS=','
  read -ra ext_array <<<"${ext_list}"
  unset IFS
  # Validate each extension
  local ext
  for ext in "${ext_array[@]}"; do
    [[ "${ext}" =~ ^[a-zA-Z0-9]+$ ]] || {
      log_error "Invalid extension format: ${ext}"
      return ${E_USAGE}
    }
  done

  EXTENSIONS=("${ext_array[@]}")
  return 0
}

# Validates numeric parameters against allowed ranges
# Args:
#   $1 - Parameter name for error messages
#   $2 - Parameter value to validate
#   $3 - Minimum allowed value (optional)
#   $4 - Maximum allowed value (optional)
# Returns:
#   0 on success, E_USAGE on validation failure
function parse_numeric() {
  local param_name="$1"
  local param_value="$2"

  local min_value="${3:-0}"
  local max_value="${4:-0}"

  if [[ ! "${param_value}" =~ ^[0-9]+$ ]]; then
    log_error "Invalid ${param_name}: ${param_value} (must be numeric)"
    return "${E_USAGE}"
  fi

  if ((param_value < min_value)); then
    log_error "Invalid ${param_name}: ${param_value} (must be >= ${min_value})"
    return "${E_USAGE}"
  fi

  if ((param_value > max_value)); then
    log_error "Invalid ${param_name}: ${param_value} (must be <= ${max_value})"
    return "${E_USAGE}"
  fi

  return 0
}

# Validates and normalizes input path
# Ensures path exists, is readable, and is within allowed directories
# Args:
#   $1 - Path to validate
# Returns:
#   Absolute path on success, non-zero error code on failure

function parse_path() {
  local path="$1"
  local abs_path

  [[ -z "${path}" ]] && {
    log_error "Path cannot be empty"
    return ${E_USAGE}
  }

  # Debug output
  if ((DEBUG)); then
    log_debug "Parsing path: ${path}"
    log_debug "Path exists: $([[ -e "${path}" ]] && echo "yes" || echo "no")"
    log_debug "Path is directory: $([[ -d "${path}" ]] && echo "yes" || echo "no")"
  fi

  # Try different realpath options
  if ! abs_path=$(realpath -L -m "${path}" 2>/dev/null); then
    if ! abs_path=$(realpath -L "${path}" 2>/dev/null); then
      if ! abs_path=$(readlink -f "${path}" 2>/dev/null); then
        log_error "Cannot resolve path: ${path}"
        return ${E_PATH}
      fi
    fi
  fi

  if ((DEBUG)); then
    log_debug "Resolved path: ${abs_path}"
    log_debug "Allowed paths: ${ALLOWED_PATHS[*]}"
  fi

  # Check if path is within allowed directories
  local allowed
  for allowed in "${ALLOWED_PATHS[@]}"; do
    if [[ "${abs_path}" = "${allowed}"/* ]]; then
      echo "${abs_path}"
      return 0
    fi
  done

  log_error "Path not within allowed directories: ${path}"
  return ${E_SECURITY}
}

# Parses command line arguments and sets global configuration
# Args:
#   All command line arguments ($@)
# Returns:
#   0 on success, non-zero on error
function parse_args() {
  local -a args=()
  local arg opt

  # Transform long options to short ones
  for arg; do
    case "$arg" in
      --help)         args+=(-h) ;;
      --debug)        args+=(-d) ;;
      --verbose)      args+=(-v) ;;
      --quiet)        args+=(-q) ;;
      --dry-run)      args+=(-n) ;;
      --version)      version; exit 0 ;;
      --extensions=*) args+=(-e "${arg#*=}") ;;
      --jobs=*)       args+=(-j "${arg#*=}") ;;
      --max-size=*)   args+=(-m "${arg#*=}") ;;
      --output=*)     args+=(-o "${arg#*=}") ;;
      --exclude=*)    args+=(-x "${arg#*=}") ;;
      --*=*)         log_error "Unknown option: ${arg}"; return ${E_USAGE} ;;
      --*)           log_error "Unknown option: ${arg}"; return ${E_USAGE} ;;
      *)             args+=("$arg") ;;
    esac
  done

  # Reset the positional parameters to the short options
  set -- "${args[@]}"

  local OPTIND opt
  while getopts ":de:hj:m:no:qvx:" opt; do
    case "${opt}" in
      d) # Debug
        LOG_LEVEL=${LOG_LEVEL_DEBUG}
        ;;
      e) # Extensions
        parse_extensions "${OPTARG}" || return ${E_USAGE}
        ;;
      h) # Help
        usage
        exit 0
        ;;
      j) # Max parallel jobs
        parse_numeric "jobs" "${OPTARG}" 1 || return ${E_USAGE}
        MAX_JOBS="${OPTARG}"
        ;;
      m) # Max file size
        parse_numeric "max-size" "${OPTARG}" || return ${E_USAGE}
        MAX_SIZE="${OPTARG}"
        ;;
      n) # Dry run
        DRY_RUN=1
        ;;
      o) # Output path
        OUTPUT=$(parse_path "${OPTARG}") || return ${E_USAGE}
        ;;
      q) # Quiet mode
        LOG_LEVEL=${LOG_LEVEL_ERROR}
        ;;
      v) # Verbose
        [[ ${LOG_LEVEL} -lt ${LOG_LEVEL_DEBUG} ]] && LOG_LEVEL=${LOG_LEVEL_INFO}
        ;;
      x) # Exclude directories
        parse_exclude_dirs "${OPTARG}" || return ${E_USAGE}
        ;;
      :) # Missing argument
        log_error "Option -${OPTARG} requires an argument"
        return ${E_USAGE}
        ;;
      *) # Unknown option
        log_error "Invalid option: -${OPTARG}"
        return ${E_USAGE}
        ;;
    esac
  done

  shift $((OPTIND - 1))

  # Handle positional argument (path)
  if [[ $# -gt 1 ]]; then
    log_error "Too many arguments. Only one PATH argument is allowed."
    return ${E_USAGE}
  elif [[ $# -eq 1 ]]; then
    INPUT_PATH=$(parse_path "$1") || return ${E_USAGE}
  fi

  return 0
}

# Validates the final configuration settings
# Ensures all required parameters are set and valid
# Returns:
#   0 if valid, non-zero otherwise
function validate_config() {
    local -i errors=0
    local context="input=${INPUT_PATH} output=${OUTPUT}"

    # Validate required extensions
    if ((DRY_RUN == 0)) && ((${#EXTENSIONS[@]} == 0)); then
        log_error "No file extensions specified" "${context}"
        return "${E_USAGE}"
    fi

    # Validate numeric parameters
    if ((MAX_SIZE < 0)); then
        log_error "Invalid max size: ${MAX_SIZE}" "${context}"
        ((errors++))
    fi

    if ((MAX_FILES < 0)); then
        log_error "Invalid max files: ${MAX_FILES}" "${context}"
        ((errors++))
    fi

    if ((MAX_DEPTH < 0)); then
        log_error "Invalid max depth: ${MAX_DEPTH}" "${context}"
        ((errors++))
    fi

    if ((MAX_JOBS < 1)); then
        log_error "Invalid max jobs: ${MAX_JOBS}" "${context}"
        ((errors++))
    fi

    # Validate input path
    if [[ ! -e "${INPUT_PATH}" ]]; then
        log_error "Input path does not exist: ${INPUT_PATH}" "${context}"
        ((errors++))
    elif [[ ! -r "${INPUT_PATH}" ]]; then
        log_error "Input path is not readable: ${INPUT_PATH}" "${context}"
        ((errors++))
    fi

    # Validate output path
    if [[ "${OUTPUT}" != "/dev/stdout" ]]; then
        local output_dir
        output_dir="$(dirname "${OUTPUT}")"
        if [[ ! -d "${output_dir}" ]] && ! mkdir -p "${output_dir}"; then
            log_error "Cannot create output directory: ${output_dir}" "${context}"
            ((errors++))
        elif [[ -e "${OUTPUT}" && ! -w "${OUTPUT}" ]]; then
            log_error "Output file exists but is not writable: ${OUTPUT}" "${context}"
            ((errors++))
        fi
    fi

    return $((errors > 0 ? E_USAGE : 0))
}

function process_output() {
  local -r output_buffer="$1"
  local -r final_output="$2"

  if [[ "${final_output}" == "/dev/stdout" ]]; then
    # Output the content
    cat "${output_buffer}" || {
      log_error "Failed to read output buffer"
      return ${E_IO}
    }
  else
    cp "${output_buffer}" "${final_output}" || {
      log_error "Failed to write to output file: ${final_output}"
      return ${E_IO}
    }
  fi
}

#######################################
# Main execution
#######################################

# Initialize script environment and parse arguments
# Args:
#   Command line arguments ($@)
# Returns:
#   0 on success, non-zero on error
function init() {

  parse_args "$@" || return $?
  validate_config || return $?

  if ! TEMP_DIR=$(mktemp -d); then
    log_error "Failed to create temp directory: ${TEMP_DIR}"
    return "${E_IO}"
  fi

  if [[ "${OUTPUT}" != "/dev/stdout" ]]; then
    mkdir -p "$(dirname "${OUTPUT}")" || {
      log_error "Failed to create output directory"
      return ${E_IO}
    }
  fi
  return 0
}

# Improved cleanup with better error handling
function cleanup() {
    local -r exit_code=$?
    local -i ret=0
    local context="exit_code=${exit_code}"

    log_debug "Starting cleanup" "${context}"

    # Kill any remaining background jobs
    local pids
    pids=$(jobs -p)
    if [[ -n "${pids}" ]]; then
        log_debug "Terminating background jobs" "pids=${pids}"
        kill -TERM ${pids} 2>/dev/null || true
        sleep 1
        kill -KILL ${pids} 2>/dev/null || true
    fi

    # Clean up temporary files
    if ((${#TMP_FILES[@]} > 0)); then
        for tmp_file in "${TMP_FILES[@]}"; do
            if [[ -f "${tmp_file}" ]]; then
                if ! rm -f "${tmp_file}"; then
                    log_warn "Failed to remove temporary file" "file=${tmp_file}"
                    ((ret++))
                fi
            fi
        done
    fi

    # Remove temporary directory
    if [[ -d "${TEMP_DIR}" ]]; then
        if ! rm -rf "${TEMP_DIR}" 2>/dev/null; then
            log_warn "Failed to remove temporary directory" "dir=${TEMP_DIR}"
            ((ret++))
        fi
    fi

    context+=" cleanup_errors=${ret}"
    log_debug "Cleanup completed" "${context}"

    # Only exit if called directly, not through trap
    [[ "${FUNCNAME[1]}" != "handle_interrupt" ]] && \
    [[ "${FUNCNAME[1]}" != "handle_term" ]] && \
        exit $((exit_code + ret))
}

# Set up signal handlers
trap handle_interrupt INT
trap handle_term TERM
trap cleanup EXIT

# Main execution function of the script
# Args:
#   Command line arguments ($@)
# Returns:
#   0 on success, error code on failure
function main() {
    STATS_START_TIME=$(date +%s)

    if ! init "$@"; then
        log_error "Initialization failed" "args=$*"
        exit ${E_RESOURCE}
    fi

    local context="input=${INPUT_PATH} output=${OUTPUT} dry_run=${DRY_RUN}"
    log_info "Starting processing" "${context}"

    if ((DRY_RUN)); then
        log_info "Dry run mode enabled" "${context}"
        return 0
    fi

    local output_buffer
    output_buffer=$(create_temp_file) || exit ${E_IO}

    if ! process_target "${INPUT_PATH}" "${output_buffer}"; then
        log_error "Processing failed" "${context}"
        exit ${E_IO}
    fi

    if ! process_output "${output_buffer}" "${OUTPUT}"; then
        log_error "Failed to write final output" "${context}"
        exit ${E_IO}
    fi

    STATS_END_TIME=$(date +%s)
    local -i duration=$((STATS_END_TIME - STATS_START_TIME))
    
    context+=" processed=${STATS_PROCESSED}"
    context+=" failed=${STATS_FAILED}"
    context+=" duration=${duration}s"
    log_info "Processing completed" "${context}"
    return 0
}

# Execute main function if script is not being sourced
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
  main "$@"
fi
